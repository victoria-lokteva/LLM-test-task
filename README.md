# Отчет по задаче


## Решение ML стеком

Результаты можно посмотреть в ctr.ipynb

Для предсказания ctr использовались модели Catboost, LightGBM.

Обработка данных производится функцией preprocessing из скрипта ml/preprocessing.py

## Решение с помощью LLM


В качестве LLM использовалась GPT4all (в отличие от рекомендуемых в задании GPT 4, она бесплатна, 
и в отличие от Bard поддерживается langchain. Более того это open-source модель).

Большая проблема, что эта модель не генерирует код и отвечает на вопросы значительно хуже чем GPT4, 
но решение можно легко адаптировать под GPT-4 и получить намного лучшие результаты (однако у меня нет подписки на GPT-4).

Краткое описание файлов:

В скрипте agent реализована основная часть пайплайна. 

В скрипте templates содержатся контексты для пользовательских промптов.

В скрипте examples лежат примеры для few-shot learning (пока готов только 1 пример).

Сгенерированный код для ответов на промпты лежит в папке generated_code.



### Что еще можно сделать

1) Так как использованная здесь GPT4all  -- open-source модель, то здесь можно применить prompt-tuning. 
Для этого придется хотя бы прописать пару десятков примеров, заморозить все веса кроме эмбеддингов 
и обучиться получать эмбеддинги промптов, которые дадут лучшие результаты.

2) Использовать autogpt для автоматической декомпозиции задания в скрипте.

3) Прописать хотя бы десяток примеров для few-shot learning.